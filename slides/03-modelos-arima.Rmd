---
title: "Modelagem de Séries Temporais"
author: "<img src = 'https://d33wubrfki0l68.cloudfront.net/9b0699f18268059bdd2e5c21538a29eade7cbd2b/67e5c/img/logo/cursor1-5.png' width = '20%'>"
date: ""
output:
  xaringan::moon_reader:
    css: ["css/xaringan-themer.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
knit: pagedown::chrome_print
---

```{r, child="00-preamble.Rmd"}

```

```{r, include = FALSE}

library(tidyverse)
library(ggplot2)

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, error = FALSE, fig.height = 8, fig.width = 12)

```


class: middle, center

---

# Modelos AR

- No nosso exemplo de suavização exponencial temos a fórmula:

$$\hat{y}(t) = \alpha y(t) + (1-\alpha)\hat{y}(t-1)$$
Como a mesma fórmula funciona para $t-1$, também temos que:

$$\hat{y}(t-1) = \alpha y(t-1) + (1-\alpha)\hat{y}(t-2)$$
Substituindo fica:

$$\hat{y}(t) = \alpha y(t) + (1-\alpha)\alpha y(t-1) + (1-\alpha)^2\hat{y}(t-2).$$
Logo, estamos construindo uma previsão $\hat{y}$ que é a média das anteriores, mas uma média que dá muito mais peso para a primeira do que as anteriores.

---

# Modelos AR

- De fato, modelos com essa cara são importantes e recebem até um nome específico: modelos auto-regressivos. Nesses modelos, a equação da nossa previsão é parecida com:

$$y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2}$$
Claro que podemos pegar muitos dados para trás: 
$$y_t = \phi_1y_{t-1}+\phi_2 y_{t-2} + ... \phi_{p}y_{t-p}$$
Normalmente admitimos que essa equação tem algum tipo de erro, então, parecido com o caso de uma regressão, dizemos que o modelo tem um erro $\epsilon_t$ ruído branco:

$$y_t = \phi_1y_{t-1}+\phi_2 y_{t-2} + ... \phi_{p}y_{t-p} + \epsilon_t$$
Dizemos que esse modelo é Auto-Regressivo de ordem $p$ ou $AR(p)$

---

# Exemplos de modelos AR

Modelos AR normalmente desenham retinhas em que pontos próximos são parecidos:

escolhendo $p = 1$ e $\phi_1 = 0.9$

```{r, echo = FALSE}

pesos = c(0, 0, 0, 0, 0, 0, 0)

sigma = .2

N <- 100

monta_AR <- function(pesos, NN = 100, sigma = .5){
  
  y = vector("numeric")
  
  y[1] = 0
  y[2] = 0
  y[3] = 0
  y[4] = 0
  y[5] = 0
  y[6] = 0
  y[7] = 0
  
  for(i in 8:NN){
    y[i] = sum(y[(i-7):(i-1)]*pesos) + rnorm(1, sd = sigma)
  }
  
  return(y)
  
}

pesos = c(0, 0, 0, 0, 0, 0, 0.9)

tibble(
  y = monta_AR(pesos, NN = 1000)) |> 
  mutate(
  t = 1:n()
) |> 
  ggplot(aes(x = t, y = y)) + 
  geom_line()+
  theme_bw()
```

---

# Exemplos de modelos AR

Note como esse desenho é diferente do ruído branco:

Inclusive, o ruído branco aparece quando escolhemos $p = 1$ e $\phi_1 = 0$

```{r, echo = FALSE}
pesos = c(0, 0, 0, 0, 0, 0, 0)

tibble(
  y = monta_AR(pesos, NN = 1000)) |> 
  mutate(
  t = 1:n()
) |> 
  ggplot(aes(x = t, y = y)) + 
  geom_line()+
  theme_bw()
```

---

# Exemplos de modelos AR

Exemplo muito especial: 

O gráfico abaixo, um AR com $p = 1$ e $\phi_1 = 1$, te lembra alguma coisa?

```{r, echo = FALSE}
pesos = c(0, 0, 0, 0, 0, 0, 1)

tibble(
  y = monta_AR(pesos, NN = 1000)) |> 
  mutate(
  t = 1:n()
) |> 
  ggplot(aes(x = t, y = y)) + 
  geom_line()+
  theme_bw()
```

---

# Porque o modelo auto regressivo é importante?

- Alguns fenômenos são quase que perfeitamente 
modelos AR, como o preço de uma ação, por exemplo.

- Gráficos de ACF e PACF, que as vezes são meio difícies de interpretar, tem padrões específicos no modelo. 

- O AR(1), por exemplo, tem uma ACF bem especial

- Modelos auto-regressivos costumam ter ACF que decaem rápido, mas ficam um bom tempo longe do zero. No caso do AR(1), a ACF tem até fórmula:

$$ACF(t) = \phi_1^t$$

---

# ACF do AR(1)

Vamos pensar no porque isso é desse jeito com $\phi_1 = .8$

```{r, echo = FALSE}
pesos = c(0, 0, 0, 0, 0, 0, .8)

tibble(
  y = monta_AR(pesos, NN = 1000)) |> 
  mutate(
  t = 1:n()
) |> 
  with(acf(y))
```

---

# ACF de um AR com coeficiente negativo

Quando $\phi$ é negativo fica mais estranho:

$\phi_1 = -.8$

```{r, echo = FALSE}
pesos = c(0, 0, 0, 0, 0, 0, -.8)

tibble(
  y = monta_AR(pesos, NN = 1000)) |> 
  mutate(
  t = 1:n()
) |> 
  with(acf(y))
```

---

# PACF

Justamente pensando no impacto "persistente" do passado na série como um todo, foi invetado o conceito de **F**unção **A**uto **C**orrelação **P**arcial. Ela é que nem a auto correlação, mas ao invés de fazer a correlação diretamente, ela "limpa" os efeitos persistentes fazendo regressões.

Por exemplo, vamos pensar no modelo AR(1):

$$y_t = y_{t-1} + \epsilon_t$$
$$y_{t-1} = y_{t-2}+\epsilon_{t-1} \implies y_{t-2} = y_{t-1}-\epsilon_{t-1}$$

Como tanto o $y_t$ quanto o $y_{t-2}$ podem ser escritos em função de $y_{t-1}$, é natural que eles sejam correlacionados: eles são montados a partir do mesmo número. O que a PACF faz é calcular a correlação entre $\epsilon_{t-1}$ e $\epsilon_{t}$, esses sim são não rorrelacionados.

---

# PACF na prática

A PACF na prática nos ajuda a identificar o grau adequado de autocorrelação de uma série. Note como é a forma da PACF de um AR(1) com $\phi_1=.8$

```{r}
pesos = c(0, 0, 0, 0, 0, 0, .8)

tibble(
  y = monta_AR(pesos, NN = 1000)) |> 
  mutate(
  t = 1:n()
) |> 
  with(pacf(y))
```

---

# PACF na prática

PACF de um AR(2) e $\phi_1=.7$ e $\phi_2=.3$

```{r}
pesos = c(0, 0, 0, 0, 0, .3, .7)

tibble(
  y = monta_AR(pesos, NN = 1000)) |> 
  mutate(
  t = 1:n()
) |> 
  with(pacf(y))
```

---

# PACF na prática

```{r, include = FALSE}
anac <- readRDS("../dados/anac-sp.rds")

library(tsibble)
library(tidyverse)
library(feasts)

anac_ts <- anac %>%
  mutate(DATA_ym = tsibble::yearmonth(paste(ANO, MES, sep = "-"))) %>%
  mutate(
    TEMPO_DESDE_INICIO = difftime(
      DATA,
      lubridate::ymd("1999-12-01"),
      units = "days"
    )/30,
    LAG_1 = lag(PASSAGEIROS_PAGOS, 1, default = 0)
  ) |> 
  as_tsibble(index = DATA_ym) |>
  select(PASSAGEIROS_PAGOS, everything()) |> 
  filter(DATA_ym <= as.Date("2019-12-31"))

autoplot(anac_ts) +
  theme_bw()
```

---

# PACF na prática

ACF com bastante autocorrelação:

```{r}

anac_ts |> 
  ACF() |> 
  autoplot() +
  theme_bw()

```

---

# PACF na prática

PACF consegue identificar que muita dessa correlação é reduntante, temos uma autocorrelação no primeiro grau muito alta e talvez uma autocorrelação de ordem maior.

```{r}

anac_ts |> 
  PACF() |> 
  autoplot() +
  theme_bw()

```

---

# Como modelos alterar um modelo AR

Pensar em um AR ajuda a interpretar auto-correlações, mas as PACFs típicas de um modelo AR são muito rígidas. A PACF da série da ANAC não concorda com um AR simples:

```{r}
pesos = c(0, 0, 0, 0, 0, 0, .9)

tibble(
    y = monta_AR(pesos, NN = 1000)) |> 
    mutate(
        t = 1:n()
    ) |> 
    ggplot(aes(x = t, y = y)) + 
    geom_line()+
    theme_bw()
```

---

# Processo MA

Uma média móvel usa uma ideia parecida com a do AR para montar um modelo que se parece com o ruído branco, mas é varia menos em janelas próximas

$$y_t = \epsilon_t + \theta_1\epsilon_{t-1}+...+\theta_q\epsilon_{t-q}$$

---

# Ruído branco (de novo)

```{r}
monta_MA <- function(pesos, NN = 100, sigma = .5){
  
  y = vector("numeric")
  
  y[1] = 0
  y[2] = 0
  y[3] = 0
  y[4] = 0
  y[5] = 0
  y[6] = 0
  y[7] = 0
  
  eps = rnorm(NN*2, sd = sigma)
  
  for(i in 8:NN){
    y[i] = sum(eps[(i-7):(i-1)]*pesos)+eps[i]
  }
  
  return(y)
  
}

#pesos = c(0, 0, 0, 0, 0, 0, 0)

tibble(
    y = as.numeric(arima.sim(n = 100, list(ma = c(0))))) |> 
    mutate(
        t = 1:n()
    ) |> 
    ggplot(aes(x = t, y = y)) + 
    geom_line()+
    theme_bw()
```

---

# Média movel

Vamos escolher $q=1$ e $\theta_1 = 0.9$

```{r}
monta_MA <- function(pesos, NN = 100, sigma = .5){
  
  y = vector("numeric")
  
  y[1] = 0
  y[2] = 0
  y[3] = 0
  y[4] = 0
  y[5] = 0
  y[6] = 0
  y[7] = 0
  
  eps = rnorm(NN*2, sd = sigma)
  
  for(i in 8:NN){
    y[i] = sum(eps[(i-7):(i-1)]*pesos)+eps[i]
  }
  
  return(y)
  
}

pesos = c(0, 0, 0.9, 0.9, 0.9, 0.9, 0.9)

tibble(
    y = as.numeric(arima.sim(n=100, list(ma = c(0.9))))) |> 
    mutate(
        t = 1:n()
    ) |> 
    ggplot(aes(x = t, y = y)) + 
    geom_line()+
    theme_bw()
```

---

# ACF do modelo MA(q)

$q=1$ e $\theta_q = 0.9$

```{r}
pesos = c(0, 0, 0.9, 0.9, 0.9, 0.9, 0.9)

arima.sim(n=100, list(ma = c(0.9))) |> 
  acf()

```

---

# ACF do modelo MA(q)

$q=2$ e $\theta_1 = 0.9$, $\theta_2 = 0.9$

```{r}
pesos = c(0, 0, 0.9, 0.9, 0.9, 0.9, 0.9)

arima.sim(n=300, list(ma = c(0.9, 0.9))) |> 
  acf()

```

---

# Processo ARMA

Um processo ARMA é um processo que mistura a parte autoregressiva com o resíduo média móvel, que pode ter correlações em um janela específica. Isso garante que o "desenho" de um processo arma é menos dentado do que um modelo auto regressivo simples. Considere essa simulação de um ARMA(1,1):

```{r}
tibble(
    y = as.numeric(arima.sim(n = 200, list(ar = c(.9), ma = c(.9))))
    ) |> 
    mutate(
        t = 1:n()
    ) |> 
    ggplot(aes(x = t, y = y)) + 
    geom_line()+
    theme_bw()
```

---

# ARMA(1, 6)

```{r}
tibble(
    y = as.numeric(arima.sim(n = 200, list(ar = c(.9), ma = c(.9, .9, .9, .9, .9, .9, .9))))
    ) |> 
    mutate(
        t = 1:n()
    ) |> 
    ggplot(aes(x = t, y = y)) + 
    geom_line()+
    theme_bw()
```

---

# Intuição geral

Um modelo ARMA é um modelo:

- De caráter **Auto Regressivo**: $y_t$, $y_{y-1}$, $y_{t-2}$ etc podem ter relação direta e persistente entre eles.
- Com resíduos em **Média Movel**: $y_{t-1}$ vai a $y_{t}$ de maneira suave, similar ao jeito que $y_{t-2}$ foi a $y_{t-1}$

Aparentemente olhando todos os modelos $ARMA(p,q)$ temos uma grande ferramenta para ajustarmos praticamente qualquer série temporal, mas faltam dois elementos **tendência** e **sazonalidade**.

---

# Diferenças

Um jeito rudimentar de "limpar" uma série temporal de tendência e possivelmente de sazonalidade é através do método das diferenças. Isso é, criar uma nova série temporal $d$ da seguinte forma:

$$d_t = y_{t}-y_{t-1}$$
---

# Voltando à série da ANAC

Essa série tem tendência e possivelmente também tem sazonalidade:

```{r}
anac_ts |> 
  autoplot()
```

---

# Diferenças da série da ANAC

Aqui a tendência sumiu:

```{r}

anac_ts  |> 
  mutate(
    diferenca = PASSAGEIROS_PAGOS-lag(PASSAGEIROS_PAGOS)
  ) |> 
  autoplot(diferenca)

```

---

# ACF da série de Diferenças da ANAC

```{r}

anac_ts  |> 
  mutate(
    diferenca = PASSAGEIROS_PAGOS-lag(PASSAGEIROS_PAGOS),
    diferenca_12 = diferenca - lag(diferenca, 12)
  ) |> 
  ACF(diferenca) |> 
  autoplot()

```

---

# PACF da série de Diferenças da ANAC

```{r}

anac_ts  |> 
  mutate(
    diferenca = PASSAGEIROS_PAGOS-lag(PASSAGEIROS_PAGOS),
    diferenca_12 = diferenca - lag(diferenca, 12)
  ) |> 
  PACF(diferenca) |> 
  autoplot()

```

---

# Diferença da diferença

Aqui a série talvez já possa ser modelada adequadamente por um ARMA...

```{r}

anac_ts  |> 
  mutate(
    diferenca = PASSAGEIROS_PAGOS-lag(PASSAGEIROS_PAGOS),
    diferenca_12 = diferenca - lag(diferenca, 12)
  ) |> 
  autoplot(diferenca_12)

```

---

# ACF da série de Diferenças da ANAC

```{r}

anac_ts  |> 
  mutate(
    diferenca = PASSAGEIROS_PAGOS-lag(PASSAGEIROS_PAGOS),
    diferenca_12 = diferenca - lag(diferenca, 12)
  ) |> 
  PACF(diferenca_12) |> 
  autoplot()

```

---

# Modelo ARIMA

Assim como sugerimos no último exemplo, um modelo ARIMA nada mais é que um modelo ARMA (auto regressivo e com resíduo em média móvel) ajustado à uma (ou mais) diferenças de uma série temporal. Justamente por essa característica, fora os pesos, um modelo ARIMA costima vir acompanhando de três letras:

- $p$ que vem do $AR(p)$,
- $d$ que vem da ordem da diferença (se é diferença simples, ou diferença da diferença, ou diferença da diferença da diferença etc)
- $q$ que vem do $MA(q)$

Logo, um $ARIMA(p, 1, q)$ seria:

$$y_{t}-y_{t-1} = d_t \sim ARMA(p, q)$$
Já um $ARIMA(p, 2, q)$ seria: 

$$d_t - d_{t-1} = y_{t}-y_{t-1}-y_{t-1}+y_{t-2} \sim ARMA(p, q)$$
